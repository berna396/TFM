\chapter{Pruebas}

Con el fin de comprobar el correcto funcionamiento de la solución se realizarán distintas pruebas para corroborar que las alertas se generan correctamente y en un tiempo que pueda ser comprendido dentro de un sistema near real time. Para ello se obtendrá un conjunto de logs correctos y errores que se querrá identificar como una alerta (tanto de un error conocido con un error desconocido) con el objetivo de forzar una alerta y así comprobar que se recibe dentro del margen temporal esperado.

Debido a esto será necesario un trabajo previo de separación de logs en operaciones con errores y operaciones con funcionamiento correcto. Esto se llevará a cabo con un script Python, que separará en ficheros los dos tipos de operaciones a partir de logs producidos en un entorno no productivo de la aplicación. Una vez realizada la separación se podrá replicar el comportamiento de la aplicación a monitorizar, para lo que se desarrollarán dos scripts Python con las siguientes funciones:

\begin{itemize}
\item Script de carga inicial que permita una ingesta de datos hasta el tamaño deseado en Elastic Search. Para controlar el tamaño de datos cargados en elastic se podrá utilizar el comando:

\begin{verbatim}
curl 'elasticsearch:9200/_cat/indices?v' -H "Authorization: Basic ********************"
\end{verbatim}

\item Script que permita la publicación de logs en Kafka que reciba como entrada la cantidad de operaciones que se publican por segundo, el número de operaciones correctas que se publicarán hasta que se envíe el error y el tipo de error (conocido o desconocido).
\end{itemize}

Con esto conseguimos proporcionar el estado de alarma bajo demanda y así poder comprobar la respuesta en distintas situaciones. Por otro lado se desarrollará otro script que funcione como productor de la ingesta inicial de datos.

También interesa medir si se la información obtenida de aplicar la detección de anomalías sobre la traza de logs de errores desconocidos se considere útil. Para ello una vez obtenida la alerta en el informe generado deberá estar resaltado aquellas líneas de log que en un trabajo previo se han clasificado como las que contienen la causa de la incidencia.`

\subsection{Pruebas de Alertas y Rendimiento}

Para comprobar que las alertas aportan una ayuda y mejora al sistema real, se deberá probar que efectivamente se generan las alertas y se definirá un máximo de tiempo desde que se produce la incidencia hasta que el sistema la notifica. Se ha de tener en cuenta que se está trabajando sobre un prototipo que no corre sobre un sistema en producción. Debido a la menor capacidad de computo se generarán un número inferior de logs por segundo que el sistema real y se esperarán tiempos inferiores a 5 minutos entre el registro de la incidencia en los logs y la recepción del correo con la alerta. Se probarán distintos números de logs generados por segundo que sirva de estimación de comportamiento en el sistema real, así como distintos números de reglas de alertas desplegadas.

Con la realización de las pruebas se intentará conseguir tres objetivos:

\begin{itemize}


	\item \textbf{Ejecución correcta}: Se deberá comprobar que efectivamente se genera una alerta cuando se produce una incidencia en el sistema. Para que esto se considere correcto deberá generarse siempre una alerta en cada uno de los casos de prueba propuestos.

	\item \textbf{Obtención de la alerta en Near Real Time}: en caso de que el primer punto se valide correctamente, también se ha de comprobar el tiempo que transcurre desde que se genera la incidencia (en este caso mockeandola) hasta que la alerta es recibida es inferior al tiempo estimado.

	\item \textbf{Medida de recursos utilizados}: ya que los distintos componentes de la solución estarán desplegados en docker se deberá comprobar como afecta una escalada en el las cantidades de logs a analizar con el fin de estimar que recursos serían necesarios para poder tratar con el sistema real. Se tomará de medida el uso de CPU y memoria.

\end{itemize}

Para cada una de las pruebas con distintos número de reglas desplegadas se realizará el siguiente procedimiento:

\begin{enumerate}
	\item Despliegue de los contenedores Docker con la configuración y sin datos cargados.
	\item Para cada prueba individual se realiza la ingesta inicial de los datos   hasta el tamaño propuesto.
	\item Ejecución del script que genera la alarma con números distintos de reglas desplegadas.
	\item Registro de tiempos de respuesta y de recursos utilizados en los contenedores.
	\item Los puntos 4 y 5 se repetirá unas 5 veces y se calculará la media de los tiempos.
\end{enumerate}


Con el fin de comprobar como afecta el número de reglas que se tengan desplegadas se repetirán las pruebas con un número distinto y así establecer una aproximación de los recursos utilizados con varias pruebas. Además para facilitar el proceso durante las pruebas se establecerá que las alertas se ejecutan cuando se encuentre el primer error especificando con los parámetros:

\begin{verbatim}

# (Required, frequency specific)
# Alert when this many documents matching the query occur within a timeframe
num_events: 1

# (Required, frequency specific)
# num_events must occur within this amount of time to trigger an alert
timeframe:
    hours: 1
    
\end{verbatim}


\subsubsection{Muestra de los datos}

En la primera gráfica se mostrará la media de los tiempos obtenidos frente a los datos cargados en elastic search.

Como podemos observar un aumento substancial en la cantidad de datos de elastic search no supone un aumento significativo del tiempo de alerta. Tratándose de una POC en un entorno limitado el resultado obtenido supera con creces a lo esperado. Se puede esperar que en un entorno productivo el sistema funcione dentro de un rango de tiempo que suponga una mejora en el sistema de monitorizado. 

Por otro lado el consumo de recursos dependiendo del número de reglas es el siguiente:

Como se puede observar un aumento del número de reglas no implica un uso mas exhaustivo de los recursos. Incluso probando con un número de reglas mayor al esperando en entornos productivos el uso de memoria se puede considerar bajo.


\subsubsection{Conclusiones}

Una vez realizado el proceso de pruebas sobre el sistema se puede afirmar lo siguiente:

\begin{itemize}

\item El sistema cumple con la fiabilidad y tiempo esperado dentro de un entorno de pruebas acotado al hardware disponible.

\item Un aumento drástico en la cantidad de datos cargados en Elastic Search no supone una peor prestación en cuanto a tiempos de alertado.

\item El aumento de número de reglas no supone peores tiempos de alertado, aún que si que se puede percibir un pequeño mayor consumo de recursos. 

\end{itemize}


\subsection{Pruebas del detector de anomalías en errores desconocidos}

Como objetivo secundario de la aplicación se buscará probar que para los errores desconocidos se proporciona una herramienta que pueda ayudar a la resolución de la alerta.

Para esta prueba se han buscado operaciones fallidas con un error desconocido en las que se distinguieron claramente la causa del error. En este caso varias operaciones en las que se produjo una excepción java no controlada que llegó a registrarse.

Por otro lado, se realizará un entrenamiento inicial del modelo utilizando un conjunto logs de resultados correctos de la operación a probar. Para ello se utilizarán los logs utilizados en las pruebas de rendimiento y se filtrarán por operaciones para entrenar un modelo por operación. Una vez entrenados los modelos y aplicada la detección de anomalías se genera un informe que resalte aquellas líneas que difieran de las líneas base. 

Se definirá como correcto los casos en los que se diferencien aquellas líneas que en un trabajo previo se clasifiquen como las que aportan información para tratar la incidencia, es decir, las líneas que se consideren anómalas. El ejemplo de salida es el siguiente:

\begin{figure}[H]
\centerline{\includegraphics[width=15cm]{figuras/report.png}}
\caption{Ejemplo salida detección anomalías}
\label{enlace1}
\end{figure}


En las pruebas realizadas se han obtenido los siguientes resultados:

Positivos Correctos / Falsos Positivos

Negativos Correctos / Falsos Negativos


El resultado se considera correcto, ya que se efectivamente las líneas causantes del problema se resaltan como anomalías, sin embargo, no es un resultado perfecto, ya que también se están considerando anomalías (aunque con un valor de diferencia menor) debido al gran número de caminos y posibilidades posibles en las operaciones. Sin embargo, se considera que el resultado es lo suficientemente correcto, se espera que la salida pueda ayudar a personal no técnico encargado de la monitorización a facilitar el trabajo de revisión y búsqueda y con los resultados obtenidos se cumple esta condición.


